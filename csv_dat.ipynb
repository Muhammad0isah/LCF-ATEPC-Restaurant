{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Annotated ABSA with Emotions Dataset.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T17:17:09.547593Z",
     "start_time": "2024-06-10T17:17:09.512674Z"
    }
   },
   "id": "db05a290a2fb23cc",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4833 entries, 0 to 4832\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               2415 non-null   float64\n",
      " 1   Review Sentence  4833 non-null   object \n",
      " 2   Aspect term      4832 non-null   object \n",
      " 3   polarity         4833 non-null   object \n",
      " 4   from             4833 non-null   int64  \n",
      " 5   to               4833 non-null   int64  \n",
      " 6   Anger            4831 non-null   float64\n",
      " 7   Disgust          4832 non-null   float64\n",
      " 8   Fear             4827 non-null   float64\n",
      " 9   Joy              4816 non-null   float64\n",
      " 10  Sadness          4831 non-null   float64\n",
      " 11  Surprise         4824 non-null   float64\n",
      " 12  Emotion Class    4833 non-null   object \n",
      "dtypes: float64(7), int64(2), object(4)\n",
      "memory usage: 491.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T17:17:10.007452Z",
     "start_time": "2024-06-10T17:17:09.984768Z"
    }
   },
   "id": "13756aa288d4e200",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# drop the rows with missing values\n",
    "data.dropna(subset=['Aspect term'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T17:17:11.099100Z",
     "start_time": "2024-06-10T17:17:11.086249Z"
    }
   },
   "id": "a0a8a8aef393e8fc",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4832 entries, 0 to 4832\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               2414 non-null   float64\n",
      " 1   Review Sentence  4832 non-null   object \n",
      " 2   Aspect term      4832 non-null   object \n",
      " 3   polarity         4832 non-null   object \n",
      " 4   from             4832 non-null   int64  \n",
      " 5   to               4832 non-null   int64  \n",
      " 6   Anger            4830 non-null   float64\n",
      " 7   Disgust          4831 non-null   float64\n",
      " 8   Fear             4826 non-null   float64\n",
      " 9   Joy              4815 non-null   float64\n",
      " 10  Sadness          4830 non-null   float64\n",
      " 11  Surprise         4823 non-null   float64\n",
      " 12  Emotion Class    4832 non-null   object \n",
      "dtypes: float64(7), int64(2), object(4)\n",
      "memory usage: 528.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T17:17:13.109633Z",
     "start_time": "2024-06-10T17:17:13.090262Z"
    }
   },
   "id": "e632568b0a5a8bb0",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# drop the Polarity  row with the value \"conflict\"\n",
    "data = data[data['polarity'] != 'conflict']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T17:17:15.012915Z",
     "start_time": "2024-06-10T17:17:15.001904Z"
    }
   },
   "id": "36d7f9804d201a21",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "polarity\npositive    2891\nnegative    1003\nneutral      833\nName: count, dtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['polarity'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T17:17:16.177171Z",
     "start_time": "2024-06-10T17:17:16.159093Z"
    }
   },
   "id": "450741f6e99d731d",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:17:29.771485Z",
     "start_time": "2024-06-10T17:17:24.821016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       But O -1 -1\\nthe O -1 -1\\nstaff B-ASP 1 0\\nwas...\n",
      "1       To O -1 -1\\nbe O -1 -1\\ncompletely O -1 -1\\nfa...\n",
      "2       The O -1 -1\\nfood B-ASP 2 3\\nis O -1 -1\\nunifo...\n",
      "3       The O -1 -1\\nfood B-ASP -1 -1\\nis O -1 -1\\nuni...\n",
      "4       The O -1 -1\\nfood B-ASP -1 -1\\nis O -1 -1\\nuni...\n",
      "                              ...                        \n",
      "4828    Each O -1 -1\\ntable B-ASP -1 -1\\nhas O -1 -1\\n...\n",
      "4829    Each O -1 -1\\ntable B-ASP -1 -1\\nhas O -1 -1\\n...\n",
      "4830    Each O -1 -1\\ntable B-ASP -1 -1\\nhas O -1 -1\\n...\n",
      "4831    Each O -1 -1\\ntable B-ASP -1 -1\\nhas O -1 -1\\n...\n",
      "4832    Each O -1 -1\\ntable B-ASP -1 -1\\nhas O -1 -1\\n...\n",
      "Length: 4727, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure nltk resources are available\n",
    "#nltk.download('punkt')\n",
    "\n",
    "def get_all_aspects(data):\n",
    "    aspect_dict = {}\n",
    "    for _, row in data.iterrows():\n",
    "        sentence = row['Review Sentence']\n",
    "        aspect = row['Aspect term']\n",
    "        if sentence not in aspect_dict:\n",
    "            aspect_dict[sentence] = []\n",
    "        aspect_dict[sentence].append(aspect)\n",
    "    return aspect_dict\n",
    "def nltk_format_data(row, all_aspects):\n",
    "    # Tokenize the sentence while correctly handling punctuation\n",
    "    tokens = word_tokenize(row['Review Sentence'])\n",
    "    current_aspect = row['Aspect term']\n",
    "    polarity_code = {'positive': 2, 'neutral': 0, 'negative': 1}[row['polarity']]\n",
    "    \n",
    "    # Map emotion classes to numerical codes\n",
    "    emotion_code = {'Anger': 0, 'Disgust': 1, 'Fear': 2, 'Joy': 3, 'Sadness': 4, 'Surprise': 5} \n",
    "    \n",
    "    # Get all aspects for the current sentence\n",
    "    all_aspects_in_sentence = all_aspects[row['Review Sentence']]\n",
    "    \n",
    "    # Normalize the tokens to ensure consistent matching with aspect terms\n",
    "    normalized_tokens = [token.rstrip('.,?!:;') for token in tokens]\n",
    "    \n",
    "    formatted_sentence = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        normalized_token = normalized_tokens[i]\n",
    "        matched_aspect = None\n",
    "        \n",
    "        # Check if the token is part of any aspect term\n",
    "        for aspect in all_aspects_in_sentence:\n",
    "            aspect_tokens = aspect.split()\n",
    "            aspect_length = len(aspect_tokens)\n",
    "            if normalized_tokens[i:i+aspect_length] == aspect_tokens:\n",
    "                matched_aspect = aspect\n",
    "                break\n",
    "        \n",
    "        if matched_aspect:\n",
    "            aspect_tokens = matched_aspect.split()\n",
    "            for j, aspect_token in enumerate(aspect_tokens):\n",
    "                if j == 0:\n",
    "                    formatted_sentence.append(f\"{aspect_token} B-ASP {polarity_code if matched_aspect == current_aspect else '-1'} {emotion_code[row['Emotion Class']] if matched_aspect == current_aspect else '-1'}\")\n",
    "                else:\n",
    "                    formatted_sentence.append(f\"{aspect_token} I-ASP {polarity_code if matched_aspect == current_aspect else '-1'} {emotion_code[row['Emotion Class']] if matched_aspect == current_aspect else '-1'}\")\n",
    "            i += len(aspect_tokens)  # Skip the aspect tokens\n",
    "        else:\n",
    "            formatted_sentence.append(f\"{tokens[i]} O -1 -1\")\n",
    "            i += 1\n",
    "\n",
    "    return '\\n'.join(formatted_sentence)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get all aspects for each sentence\n",
    "all_aspects = get_all_aspects(data)\n",
    "\n",
    "# Apply NLTK formatting to the DataFrame and display the results\n",
    "example_data_nltk_formatted = data.apply(nltk_format_data, axis=1, all_aspects=all_aspects)\n",
    "print(example_data_nltk_formatted)  # Displaying formatted data for the first entry\n",
    "# print(example_data_nltk_formatted.values[1])  # Displaying formatted data for "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fdfbe328dc692745"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "example_data_nltk_formatted.to_csv('example_data_nltk_formatted.dat', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-10T12:50:04.206322Z",
     "start_time": "2024-06-10T12:50:04.118770Z"
    }
   },
   "id": "c1b48b04465e7bb4",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b161d7aec7ed2c91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T17:18:03.982817Z",
     "start_time": "2024-06-10T17:18:03.841764Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Calculate the number of rows for training and testing\n",
    "train_size = int(0.75 * len(example_data_nltk_formatted))\n",
    "test_size = len(example_data_nltk_formatted) - train_size\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df = example_data_nltk_formatted.iloc[:train_size]\n",
    "test_df = example_data_nltk_formatted.iloc[train_size:]\n",
    "\n",
    "\n",
    "# Add a new line at the end of each sentence\n",
    "train_df = train_df.apply(lambda x: x + '\\n' if isinstance(x, str) else x)\n",
    "test_df = test_df.apply(lambda x: x + '\\n' if isinstance(x, str) else x)\n",
    "\n",
    "# Convert and save the training and testing data without quotes\n",
    "train_df.to_csv('Restaurants.atepc.train.dat', index=False, header=False, sep='\\t', quoting=csv.QUOTE_NONE,escapechar=\"\\t\")\n",
    "test_df.to_csv('Restaurants.atepc.test.dat', index=False, header=False, sep='\\t', quoting=csv.QUOTE_NONE,escapechar=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dd1b1ceae1b69716"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
