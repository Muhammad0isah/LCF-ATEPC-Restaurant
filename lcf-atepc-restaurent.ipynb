{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertForTokenClassification, BertPooler, BertSelfAttention\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Define hardcoded values\n",
    "max_seq_length = 128  # replace with your value\n",
    "dropout = 0.1  # replace with your value\n",
    "SRD = 3  # replace with your value\n",
    "use_unique_bert = False  # replace with your value\n",
    "local_context_focus = 'cdm'  # replace with your value\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.config = config\n",
    "        self.SA = BertSelfAttention(config)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        zero_vec = np.zeros((inputs.size(0), 1, 1, max_seq_length))\n",
    "        zero_tensor = torch.tensor(zero_vec).float().to(device)\n",
    "        SA_out = self.SA(inputs, zero_tensor)\n",
    "        return self.tanh(SA_out[0])\n",
    "\n",
    "\n",
    "class LCF_ATEPC(BertForTokenClassification):\n",
    "    def __init__(self, bert_base_model):\n",
    "        super(LCF_ATEPC, self).__init__(config=bert_base_model.config)\n",
    "        config = bert_base_model.config\n",
    "        self.bert_for_global_context = bert_base_model\n",
    "        if not use_unique_bert:\n",
    "            self.bert_for_local_context = copy.deepcopy(self.bert_for_global_context)\n",
    "        else:\n",
    "            self.bert_for_local_context = self.bert_for_global_context\n",
    "        self.pooler = BertPooler(config)\n",
    "        self.num_emotion_labels = 6\n",
    "        self.dense = torch.nn.Linear(768, 4)  # For aspect categories\n",
    "        self.emotion_classifier = nn.Linear(config.hidden_size, 6)  # 6 for the number of emotions\n",
    "        self.bert_global_focus = self.bert_for_global_context\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.SA1 = SelfAttention(config)\n",
    "        self.SA2 = SelfAttention(config)\n",
    "        self.linear_double = nn.Linear(768 * 2, 768)\n",
    "        self.linear_triple = nn.Linear(768 * 3, 768)\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self._device\n",
    "\n",
    "    @device.setter\n",
    "    def device(self, value):\n",
    "        self._device = value\n",
    "\n",
    "    def get_batch_token_labels_bert_base_indices(self, labels):\n",
    "        if labels is None:\n",
    "            return\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        for text_i in range(len(labels)):\n",
    "            sep_index = np.argmax((labels[text_i] == 5))\n",
    "            labels[text_i][sep_index + 1:] = 0\n",
    "        return torch.tensor(labels).to(self.args.device)\n",
    "    def get_batch_polarities(self, b_polarities):\n",
    "        b_polarities = b_polarities.detach().cpu().numpy()\n",
    "        shape = b_polarities.shape\n",
    "        polarities = np.zeros((shape[0]))\n",
    "        i = 0\n",
    "        for polarity in b_polarities:\n",
    "            polarity_idx = np.flatnonzero(polarity + 1)\n",
    "            try:\n",
    "                polarities[i] = polarity[polarity_idx[0]]\n",
    "            except:\n",
    "                pass\n",
    "            i += 1\n",
    "        polarities = torch.from_numpy(polarities).long().to(self.args.device)\n",
    "        return polarities\n",
    "\n",
    "    def get_batch_emotions(self, b_emotions):\n",
    "        b_emotions = b_emotions.detach().cpu().numpy()\n",
    "        batch_size = b_emotions.shape[0]\n",
    "        max_seq_length = self.args.max_seq_length\n",
    "        emotions = np.zeros((batch_size, max_seq_length))\n",
    "        for i in range(batch_size):\n",
    "            emotions[i, :len(b_emotions[i])] = b_emotions[i]\n",
    "        emotions = torch.from_numpy(emotions).long().to(self.args.device)\n",
    "        return emotions\n",
    "\n",
    "    def feature_dynamic_weighted(self, text_local_indices, polarities):\n",
    "        text_ids = text_local_indices.detach().cpu().numpy()\n",
    "        asp_ids = polarities.detach().cpu().numpy()\n",
    "        weighted_text_raw_indices = np.ones((text_local_indices.size(0), text_local_indices.size(1), 768),\n",
    "                                            dtype=np.float32)\n",
    "        SRD = self.args.SRD\n",
    "        for text_i, asp_i in zip(range(len(text_ids)), range(len(asp_ids))):\n",
    "            a_ids = np.flatnonzero(asp_ids[asp_i] + 1)\n",
    "            text_len = np.flatnonzero(text_ids[text_i])[-1] + 1\n",
    "            asp_len = len(a_ids)\n",
    "            try:\n",
    "                asp_begin = a_ids[0]\n",
    "            except:\n",
    "                asp_begin = 0\n",
    "            asp_avg_index = (asp_begin * 2 + asp_len) / 2\n",
    "            distances = np.zeros((text_len), dtype=np.float32)\n",
    "            for i in range(len(distances)):\n",
    "                if abs(i - asp_avg_index) + asp_len / 2 > SRD:\n",
    "                    distances[i] = 1 - (abs(i - asp_avg_index) + asp_len / 2 - SRD) / len(distances)\n",
    "                else:\n",
    "                    distances[i] = 1\n",
    "            for i in range(len(distances)):\n",
    "                weighted_text_raw_indices[text_i][i] = weighted_text_raw_indices[text_i][i] * distances[i]\n",
    "        weighted_text_raw_indices = torch.from_numpy(weighted_text_raw_indices)\n",
    "        return weighted_text_raw_indices.to(self.args.device)\n",
    "\n",
    "    def feature_dynamic_mask(self, text_local_indices, polarities):\n",
    "        text_ids = text_local_indices.detach().cpu().numpy()\n",
    "        asp_ids = polarities.detach().cpu().numpy()\n",
    "        SRD = self.args.SRD\n",
    "        masked_text_raw_indices = np.ones((text_local_indices.size(0), text_local_indices.size(1), 768),\n",
    "                                          dtype=np.float32)\n",
    "        for text_i, asp_i in zip(range(len(text_ids)), range(len(asp_ids))):\n",
    "            a_ids = np.flatnonzero(asp_ids[asp_i] + 1)\n",
    "            try:\n",
    "                asp_begin = a_ids[0]\n",
    "            except:\n",
    "                asp_begin = 0\n",
    "            asp_len = len(a_ids)\n",
    "            if asp_begin >= SRD:\n",
    "                mask_begin = asp_begin - SRD\n",
    "            else:\n",
    "                mask_begin = 0\n",
    "            for i in range(mask_begin):\n",
    "                masked_text_raw_indices[text_i][i] = np.zeros(768, dtype=np.float64)\n",
    "            for j in range(asp_begin + asp_len + SRD - 1, self.args.max_seq_length):\n",
    "                masked_text_raw_indices[text_i][j] = np.zeros(768, dtype=np.float64)\n",
    "        masked_text_raw_indices = torch.from_numpy(masked_text_raw_indices)\n",
    "        return masked_text_raw_indices.to(self.args.device)\n",
    "\n",
    "    def get_ids_for_local_context_extractor(self, text_indices):\n",
    "        text_ids = text_indices.detach().cpu().numpy()\n",
    "        for text_i in range(len(text_ids)):\n",
    "            sep_index = np.argmax((text_ids[text_i] == 102))\n",
    "            text_ids[text_i][sep_index + 1:] = 0\n",
    "        return torch.tensor(text_ids).to(self.args.device)\n",
    "\n",
    "    def forward(self, input_ids_spc, token_type_ids=None, attention_mask=None, labels=None, polarities=None,\n",
    "                valid_ids=None, attention_mask_label=None, emotions=None):\n",
    "        global_context_out = self.bert_for_global_context(input_ids_spc, token_type_ids, attention_mask)[0]\n",
    "        polarity_labels = self.get_batch_polarities(polarities)\n",
    "        emotion_labels = self.get_batch_emotions(emotions)\n",
    "\n",
    "        batch_size, max_len, feat_dim = global_context_out.shape\n",
    "        global_valid_output = torch.zeros(batch_size, max_len, feat_dim, dtype=torch.float32).to(self.args.device)\n",
    "        for i in range(batch_size):\n",
    "            jj = -1\n",
    "            for j in range(max_len):\n",
    "                if valid_ids[i][j].item() == 1:\n",
    "                    jj += 1\n",
    "                    global_valid_output[i][jj] = global_context_out[i][j]\n",
    "        global_context_out = self.dropout(global_valid_output)\n",
    "        ate_logits = self.classifier(global_context_out)\n",
    "        emotion_logits = self.emotion_classifier(global_context_out)\n",
    "\n",
    "        if self.args.local_context_focus is not None:\n",
    "            local_context_ids = input_ids_spc  # Define local_context_ids here\n",
    "            local_context_out = self.bert_for_local_context(input_ids_spc, token_type_ids, attention_mask)[0]\n",
    "            local_context_out = torch.mul(local_context_out, attention_mask.unsqueeze(2))\n",
    "            local_context_out = self.dropout(local_context_out)\n",
    "            if 'cdm' in self.args.local_context_focus:\n",
    "                cdm_vec = self.feature_dynamic_mask(local_context_ids, polarities)\n",
    "                cdm_context_out = torch.mul(local_context_out, cdm_vec)\n",
    "                cdm_context_out = self.SA1(cdm_context_out)\n",
    "                cat_out = torch.cat((global_context_out, cdm_context_out), dim=-1)\n",
    "                cat_out = self.linear_double(cat_out)\n",
    "            elif 'cdw' in self.args.local_context_focus:\n",
    "                cdw_vec = self.feature_dynamic_weighted(local_context_ids, polarities)\n",
    "                cdw_context_out = torch.mul(local_context_out, cdw_vec)\n",
    "                cdw_context_out = self.SA1(cdw_context_out)\n",
    "                cat_out = torch.cat((global_context_out, cdw_context_out), dim=-1)\n",
    "                cat_out = self.linear_double(cat_out)\n",
    "            elif 'fusion' in self.args.local_context_focus:\n",
    "                cdm_vec = self.feature_dynamic_mask(local_context_ids, polarities)\n",
    "                cdm_context_out = torch.mul(local_context_out, cdm_vec)\n",
    "                cdw_vec = self.feature_dynamic_weighted(local_context_ids, polarities)\n",
    "                cdw_context_out = torch.mul(local_context_out, cdw_vec)\n",
    "                cat_out = torch.cat((global_context_out, cdw_context_out, cdm_context_out), dim=-1)\n",
    "                cat_out = self.linear_triple(cat_out)\n",
    "            sa_out = self.SA2(cat_out)\n",
    "            pooled_out = self.pooler(sa_out)\n",
    "        else:\n",
    "            pooled_out = self.pooler(global_context_out)\n",
    "        pooled_out = self.dropout(pooled_out)\n",
    "        apc_logits = self.dense(pooled_out)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss(ignore_index=0)\n",
    "            loss_sen = CrossEntropyLoss()\n",
    "            ignore_index = -1\n",
    "            loss_emo = CrossEntropyLoss(ignore_index=ignore_index)\n",
    "            loss_ate = loss_fct(ate_logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            loss_apc = loss_sen(apc_logits, polarity_labels)\n",
    "            loss_emo = loss_emo(emotion_logits.view(-1, self.num_emotion_labels), emotion_labels.view(-1))\n",
    "            total_loss = loss_ate.item() + loss_apc.item() + loss_emo.item()\n",
    "            return total_loss\n",
    "        else:\n",
    "            return ate_logits, apc_logits, emotion_logits"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# file: data_utils.py\n",
    "# author: yangheng <yangheng@m.scnu.edu.cn>\n",
    "# Copyright (C) 2019. All Rights Reserved.\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define hardcoded values\n",
    "max_seq_length = 128  # replace with your value\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, sentence_label=None, aspect_label=None, polarity=None, emotion=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.sentence_label = sentence_label\n",
    "        self.aspect_label = aspect_label\n",
    "        self.polarity = polarity\n",
    "        self.emotion = emotion\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids_spc, input_mask, segment_ids, label_id, polarities=None, valid_ids=None,\n",
    "                 label_mask=None, emotions=None):\n",
    "        self.input_ids_spc = input_ids_spc\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        self.valid_ids = valid_ids\n",
    "        self.label_mask = label_mask\n",
    "        self.polarities = polarities\n",
    "        self.emotions = emotions\n",
    "\n",
    "\n",
    "def readfile(filename):\n",
    "    '''\n",
    "    read file\n",
    "    '''\n",
    "    f = open(filename, encoding='utf8')\n",
    "    data = []\n",
    "    sentence = []\n",
    "    tag = []\n",
    "    polarity = []\n",
    "    emotion = []  # Add this line\n",
    "    for line in f:\n",
    "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
    "            if len(sentence) > 0:\n",
    "                data.append((sentence, tag, polarity, emotion))  # Modify this line\n",
    "                sentence = []\n",
    "                tag = []\n",
    "                polarity = []\n",
    "                emotion = []  # Add this line\n",
    "            continue\n",
    "        splits = line.split(' ')\n",
    "        if len(splits) != 4:  # Modify this line\n",
    "            print('warning! detected error line(s) in input file:{}'.format(line))\n",
    "        sentence.append(splits[0])\n",
    "        tag.append(splits[-3])  # Modify this line\n",
    "        polarity.append(int(splits[-2]))  # Modify this line\n",
    "        emotion.append(splits[-1][:-1])  # Add this line\n",
    "\n",
    "    if len(sentence) > 0:\n",
    "        data.append((sentence, tag, polarity, emotion))  # Modify this line\n",
    "    return data\n",
    "\n",
    "\n",
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        return readfile(input_file)\n",
    "\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder to the emotions\n",
    "le.fit([\"Joy\", \"Anger\", \"Fear\", \"Sadness\", \"Surprise\", \"Disgust\", \"None\"])  # Add all possible emotions\n",
    "\n",
    "\n",
    "class ATEPCProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the CoNLL-2003 data set.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"Restaurants.atepc.train.dat\")), \"train\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"Restaurants.atepc.test.dat\")), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        # return [\"O\", \"B-ASP\", \"I-ASP\", \"[CLS]\", \"[SEP]\", \"Anger\", \"Disgust\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]\n",
    "        return [\"O\", \"B-ASP\", \"I-ASP\", \"[CLS]\", \"[SEP]\"]\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        examples = []\n",
    "        for i, (sentence, tag, polarity, emotion) in enumerate(lines):\n",
    "            aspect = []\n",
    "            aspect_tag = []\n",
    "            aspect_polarity = [-1]\n",
    "            aspect_emotion = []  # Add this line\n",
    "            for w, t, p, e in zip(sentence, tag, polarity, emotion):  # Modify this line\n",
    "                if p != -1:\n",
    "                    aspect.append(w)\n",
    "                    aspect_tag.append(t)\n",
    "                    aspect_polarity.append(-1)\n",
    "                aspect_emotion.append(e)  # Add this line\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = sentence\n",
    "            text_b = aspect\n",
    "            polarity.extend(aspect_polarity)\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, sentence_label=tag,\n",
    "                                         aspect_label=aspect_tag, polarity=polarity,\n",
    "                                         emotion=aspect_emotion))\n",
    "        return examples\n",
    "\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list, 1)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        text_spc_tokens = example.text_a\n",
    "        aspect_tokens = example.text_b\n",
    "        sentence_label = example.sentence_label\n",
    "        aspect_label = example.aspect_label\n",
    "        polaritiylist = example.polarity\n",
    "        emotionlist = example.emotion  # Add this line\n",
    "        tokens = []\n",
    "        labels = []\n",
    "        polarities = []\n",
    "        emotions = []  # Add this line\n",
    "        valid = []\n",
    "        label_mask = []\n",
    "        text_spc_tokens.extend(['[SEP]'])\n",
    "        text_spc_tokens.extend(aspect_tokens)\n",
    "        enum_tokens = text_spc_tokens\n",
    "        diff = len(enum_tokens) - len(emotionlist)\n",
    "        if diff > 0:\n",
    "            emotionlist += emotionlist * (diff // len(emotionlist)) + emotionlist[:diff % len(emotionlist)]\n",
    "        sentence_label.extend(['[SEP]'])\n",
    "        emotionlist = list(map(int, emotionlist))\n",
    "        sentence_label.extend(aspect_label)\n",
    "        label_lists = sentence_label\n",
    "        for i, word in enumerate(enum_tokens):\n",
    "            token = tokenizer.tokenize(word)\n",
    "            tokens.extend(token)\n",
    "            label_1 = label_lists[i]\n",
    "            polarity_1 = polaritiylist[i]\n",
    "            emotion_1 = emotionlist[i]\n",
    "            for m in range(len(token)):\n",
    "                if m == 0:\n",
    "                    labels.append(label_1)\n",
    "                    polarities.append(polarity_1)\n",
    "                    emotions.append(emotion_1)  # Add this line\n",
    "                    valid.append(1)\n",
    "                    label_mask.append(1)\n",
    "                else:\n",
    "                    valid.append(0)\n",
    "        if len(tokens) >= max_seq_length - 1:\n",
    "            tokens = tokens[0:(max_seq_length - 2)]\n",
    "            polarities = polarities[0:(max_seq_length - 2)]\n",
    "            emotions = emotions[0:(max_seq_length - 2)]\n",
    "            labels = labels[0:(max_seq_length - 2)]\n",
    "            valid = valid[0:(max_seq_length - 2)]\n",
    "            label_mask = label_mask[0:(max_seq_length - 2)]\n",
    "        ntokens = []\n",
    "        segment_ids = []\n",
    "        label_ids = []\n",
    "        ntokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        valid.insert(0, 1)\n",
    "        label_mask.insert(0, 1)\n",
    "        label_ids.append(label_map[\"[CLS]\"])\n",
    "        for i, token in enumerate(tokens):\n",
    "            ntokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "            if len(labels) > i:\n",
    "                label_ids.append(label_map[labels[i]])\n",
    "        ntokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "        valid.append(1)\n",
    "        label_mask.append(1)\n",
    "        label_ids.append(label_map[\"[SEP]\"])\n",
    "        input_ids_spc = tokenizer.convert_tokens_to_ids(ntokens)\n",
    "        input_mask = [1] * len(input_ids_spc)\n",
    "        label_mask = [1] * len(label_ids)\n",
    "        while len(input_ids_spc) < max_seq_length:\n",
    "            input_ids_spc.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "            label_ids.append(0)\n",
    "            valid.append(1)\n",
    "            label_mask.append(0)\n",
    "        while len(label_ids) < max_seq_length:\n",
    "            label_ids.append(0)\n",
    "            label_mask.append(0)\n",
    "        while len(polarities) < max_seq_length:\n",
    "            polarities.append(-1)\n",
    "        while len(emotions) < max_seq_length:\n",
    "            emotions.append(-1)\n",
    "        assert len(input_ids_spc) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(label_ids) == max_seq_length\n",
    "        assert len(valid) == max_seq_length\n",
    "        assert len(label_mask) == max_seq_length\n",
    "        assert len(emotions) == max_seq_length\n",
    "        features.append(\n",
    "            InputFeatures(input_ids_spc=input_ids_spc,\n",
    "                          input_mask=input_mask,\n",
    "                          segment_ids=segment_ids,\n",
    "                          label_id=label_ids,\n",
    "                          polarities=polarities,\n",
    "                          emotions=emotions,\n",
    "                          valid_ids=valid,\n",
    "                          label_mask=label_mask))\n",
    "\n",
    "    return features\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "315f80eaa5445b77"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Aug 22 19:41:55 2017\n",
    "\n",
    "@author: Quantum Liu\n",
    "\"\"\"\n",
    "'''\n",
    "Example:\n",
    "gm=GPUManager()\n",
    "with torch.cuda.device(gm.auto_choice()):\n",
    "    blabla\n",
    "\n",
    "Or:\n",
    "gm=GPUManager()\n",
    "torch.cuda.set_device(gm.auto_choice())\n",
    "'''\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "def check_gpus():\n",
    "    '''\n",
    "    GPU available check\n",
    "    http://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-cuda/\n",
    "    '''\n",
    "    if not torch.cuda.is_available():\n",
    "        print('This script could only be used to manage NVIDIA GPUs,but no GPU found in your device')\n",
    "        return False\n",
    "    elif not 'NVIDIA System Management' in os.popen('nvidia-smi -h').read():\n",
    "        print(\"'nvidia-smi' tool not found.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "if check_gpus():\n",
    "    def parse(line, qargs):\n",
    "        '''\n",
    "        line:\n",
    "            a line of text\n",
    "        qargs:\n",
    "            query arguments\n",
    "        return:\n",
    "            a dict of gpu infos\n",
    "        Pasing a line of csv format text returned by nvidia-smi\n",
    "        解析一行nvidia-smi返回的csv格式文本\n",
    "        '''\n",
    "        numberic_args = ['memory.free', 'memory.total', 'power.draw', 'power.limit']  # 可计数的参数\n",
    "        power_manage_enable = lambda v: (not 'Not Support' in v)  # lambda表达式，显卡是否滋瓷power management（笔记本可能不滋瓷）\n",
    "        to_numberic = lambda v: float(v.upper().strip().replace('MIB', '').replace('W', ''))  # 带单位字符串去掉单位\n",
    "        process = lambda k, v: (\n",
    "            (int(to_numberic(v)) if power_manage_enable(v) else 1) if k in numberic_args else v.strip())\n",
    "        return {k: process(k, v) for k, v in zip(qargs, line.strip().split(','))}\n",
    "\n",
    "\n",
    "    def query_gpu(qargs=[]):\n",
    "        '''\n",
    "        qargs:\n",
    "            query arguments\n",
    "        return:\n",
    "            a list of dict\n",
    "        Querying GPUs infos\n",
    "        查询GPU信息\n",
    "        '''\n",
    "        qargs = ['index', 'gpu_name', 'memory.free', 'memory.total', 'power.draw', 'power.limit'] + qargs\n",
    "        cmd = 'nvidia-smi --query-gpu={} --format=csv,noheader'.format(','.join(qargs))\n",
    "        results = os.popen(cmd).readlines()\n",
    "        return [parse(line, qargs) for line in results]\n",
    "\n",
    "\n",
    "    def by_power(d):\n",
    "        '''\n",
    "        helper function fo sorting gpus by power\n",
    "        '''\n",
    "        power_infos = (d['power.draw'], d['power.limit'])\n",
    "        if any(v == 1 for v in power_infos):\n",
    "            print('Power management unable for GPU {}'.format(d['index']))\n",
    "            return 1\n",
    "        return float(d['power.draw']) / d['power.limit']\n",
    "\n",
    "\n",
    "    class GPUManager():\n",
    "        '''\n",
    "        qargs:\n",
    "            query arguments\n",
    "        A manager which can list all available GPU devices\n",
    "        and sort them and choice the most free one.Unspecified\n",
    "        ones pref.\n",
    "        GPU设备管理器，考虑列举出所有可用GPU设备，并加以排序，自动选出\n",
    "        最空闲的设备。在一个GPUManager对象内会记录每个GPU是否已被指定，\n",
    "        优先选择未指定的GPU。\n",
    "        '''\n",
    "\n",
    "        def __init__(self, qargs=[]):\n",
    "            '''\n",
    "            '''\n",
    "            self.qargs = qargs\n",
    "            self.gpus = query_gpu(qargs)\n",
    "            for gpu in self.gpus:\n",
    "                gpu['specified'] = False\n",
    "            self.gpu_num = len(self.gpus)\n",
    "\n",
    "        def _sort_by_memory(self, gpus, by_size=False):\n",
    "            if by_size:\n",
    "                print('Sorted by free memory size')\n",
    "                return sorted(gpus, key=lambda d: d['memory.free'], reverse=True)\n",
    "            else:\n",
    "                print('Sorted by free memory rate')\n",
    "                return sorted(gpus, key=lambda d: float(d['memory.free']) / d['memory.total'], reverse=True)\n",
    "\n",
    "        def _sort_by_power(self, gpus):\n",
    "            return sorted(gpus, key=by_power)\n",
    "\n",
    "        def _sort_by_custom(self, gpus, key, reverse=False, qargs=[]):\n",
    "            if isinstance(key, str) and (key in qargs):\n",
    "                return sorted(gpus, key=lambda d: d[key], reverse=reverse)\n",
    "            if isinstance(key, type(lambda a: a)):\n",
    "                return sorted(gpus, key=key, reverse=reverse)\n",
    "            raise ValueError(\n",
    "                \"The argument 'key' must be a function or a key in query args,please read the documention of nvidia-smi\")\n",
    "\n",
    "        def auto_choice(self, mode=0):\n",
    "            '''\n",
    "            mode:\n",
    "                0:(default)sorted by free memory size\n",
    "            return:\n",
    "                a TF device object\n",
    "            Auto choice the freest GPU device,not specified\n",
    "            ones\n",
    "            自动选择最空闲GPU,返回索引\n",
    "            '''\n",
    "            for old_infos, new_infos in zip(self.gpus, query_gpu(self.qargs)):\n",
    "                old_infos.update(new_infos)\n",
    "            unspecified_gpus = [gpu for gpu in self.gpus if not gpu['specified']] or self.gpus\n",
    "\n",
    "            if mode == 0:\n",
    "                print('Choosing the GPU device has largest free memory...')\n",
    "                chosen_gpu = self._sort_by_memory(unspecified_gpus, True)[0]\n",
    "            elif mode == 1:\n",
    "                print('Choosing the GPU device has highest free memory rate...')\n",
    "                chosen_gpu = self._sort_by_power(unspecified_gpus)[0]\n",
    "            elif mode == 2:\n",
    "                print('Choosing the GPU device by power...')\n",
    "                chosen_gpu = self._sort_by_power(unspecified_gpus)[0]\n",
    "            else:\n",
    "                print('Given an unaviliable mode,will be chosen by memory')\n",
    "                chosen_gpu = self._sort_by_memory(unspecified_gpus)[0]\n",
    "            chosen_gpu['specified'] = True\n",
    "            index = chosen_gpu['index']\n",
    "            print('Using GPU {i}:\\n{info}'.format(i=index, info='\\n'.join(\n",
    "                [str(k) + ':' + str(v) for k, v in chosen_gpu.items()])))\n",
    "            return int(index)\n",
    "else:\n",
    "    raise ImportError('GPU available check failed')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef74f275da7c9bcc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os, sys\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from time import strftime, localtime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import device\n",
    "from transformers.optimization import AdamW\n",
    "from transformers.models.bert.modeling_bert import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from seqeval.metrics import classification_report\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "\n",
    "from utils.data_utils import ATEPCProcessor, convert_examples_to_features\n",
    "from model.lcf_atepc import LCF_ATEPC\n",
    "\n",
    "# Define hardcoded values\n",
    "max_seq_length = 128\n",
    "dropout = 0.1\n",
    "SRD = 3\n",
    "use_unique_bert = False\n",
    "local_context_focus = 'cdm'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Other hardcoded values\n",
    "dataset = 'your_dataset'\n",
    "output_dir = 'your_output_dir'\n",
    "learning_rate = 0.001\n",
    "num_train_epochs = 10\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "eval_steps = 20\n",
    "gradient_accumulation_steps = 1\n",
    "config_path = 'experiments.json'\n",
    "\n",
    "# ...\n",
    "\n",
    "def main():\n",
    "    # ...\n",
    "\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    torch.manual_seed(1)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    processor = ATEPCProcessor()\n",
    "    label_list = processor.get_labels()\n",
    "    num_labels = len(label_list) + 1\n",
    "\n",
    "    bert_model = \"bert-base-uncased\"\n",
    "    data_dir = \"atepc_datasets/restaurant\"\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_model, do_lower_case=True)\n",
    "    train_examples = processor.get_train_examples(data_dir)\n",
    "    eval_examples = processor.get_test_examples(data_dir)\n",
    "    num_train_optimization_steps = int(\n",
    "        len(train_examples) / train_batch_size / gradient_accumulation_steps) * num_train_epochs\n",
    "    bert_base_model = BertModel.from_pretrained(bert_model)\n",
    "    bert_base_model.config.num_labels = num_labels\n",
    "\n",
    "    model = LCF_ATEPC(bert_base_model, max_seq_length=max_seq_length, dropout=dropout, SRD=SRD, \n",
    "                      use_unique_bert=use_unique_bert, local_context_focus=local_context_focus, device=device)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.00001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.00001}\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, weight_decay=0.00001)\n",
    "    eval_features = convert_examples_to_features(eval_examples, label_list, args.max_seq_length,\n",
    "                                                 tokenizer)\n",
    "    all_spc_input_ids = torch.tensor([f.input_ids_spc for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "    all_polarities = torch.tensor([f.polarities for f in eval_features], dtype=torch.long)\n",
    "    all_valid_ids = torch.tensor([f.valid_ids for f in eval_features], dtype=torch.long)\n",
    "    all_lmask_ids = torch.tensor([f.label_mask for f in eval_features], dtype=torch.long)\n",
    "    all_emotions = torch.tensor([f.emotions for f in eval_features], dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_spc_input_ids, all_input_mask, all_segment_ids, all_label_ids,\n",
    "                            all_polarities, all_valid_ids, all_lmask_ids, all_emotions)  # Modify this line\n",
    "    # Run prediction for full data\n",
    "    eval_sampler = RandomSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "    def evaluate(eval_ATE=True, eval_APC=True, eval_emotion=True):\n",
    "        apc_result = {'max_apc_test_acc': 0, 'max_apc_test_f1': 0}\n",
    "        ate_result = 0\n",
    "        emotion_result = {'max_emotion_test_acc': 0, 'max_emotion_test_f1': 0}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        n_test_correct, n_test_total = 0, 0\n",
    "        test_apc_logits_all, test_polarities_all = None, None\n",
    "        test_emotion_logits_all, test_emotions_all = None, None\n",
    "        model.eval()\n",
    "        label_map = {i: label for i, label in enumerate(label_list, 1)}\n",
    "        for input_ids_spc, input_mask, segment_ids, label_ids, polarities, valid_ids, l_mask, emotions in eval_dataloader:\n",
    "            input_ids_spc = input_ids_spc.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            valid_ids = valid_ids.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "            polarities = polarities.to(device)\n",
    "            l_mask = l_mask.to(device)\n",
    "            emotions = emotions.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                ate_logits, apc_logits, emotion_logits = model(input_ids_spc, segment_ids, input_mask,\n",
    "                                                               valid_ids=valid_ids, polarities=polarities,\n",
    "                                                               attention_mask_label=l_mask, emotions=emotions)\n",
    "            if eval_APC:\n",
    "                polarities = model.get_batch_polarities(polarities)\n",
    "                n_test_correct += (torch.argmax(apc_logits, -1) == polarities).sum().item()\n",
    "                n_test_total += len(polarities)\n",
    "\n",
    "                if test_polarities_all is None:\n",
    "                    test_polarities_all = polarities\n",
    "                    test_apc_logits_all = apc_logits\n",
    "                else:\n",
    "                    test_polarities_all = torch.cat((test_polarities_all, polarities), dim=0)\n",
    "                    test_apc_logits_all = torch.cat((test_apc_logits_all, apc_logits), dim=0)\n",
    "\n",
    "            if eval_emotion:\n",
    "                emotions = model.get_batch_emotions(emotions)\n",
    "                n_test_correct += (torch.argmax(emotion_logits, -1) == emotions).sum().item()\n",
    "                n_test_total += len(emotions)\n",
    "\n",
    "                if test_emotions_all is None:\n",
    "                    test_emotions_all = emotions\n",
    "                    test_emotion_logits_all = emotion_logits\n",
    "                else:\n",
    "                    test_emotions_all = torch.cat((test_emotions_all, emotions), dim=0)\n",
    "                    test_emotion_logits_all = torch.cat((test_emotion_logits_all, emotion_logits), dim=0)\n",
    "\n",
    "            if eval_ATE:\n",
    "                # Assuming ATE evaluation is based on F1 score\n",
    "                ate_f1 = f1_score(label_ids.cpu(), torch.argmax(ate_logits, -1).cpu(), average='macro')\n",
    "                ate_result = max(ate_result, ate_f1)\n",
    "\n",
    "        if eval_APC:\n",
    "            # Assuming APC evaluation is based on accuracy\n",
    "            apc_acc = accuracy_score(test_polarities_all.cpu(), torch.argmax(test_apc_logits_all, -1).cpu())\n",
    "            apc_f1 = f1_score(test_polarities_all.cpu(), torch.argmax(test_apc_logits_all, -1).cpu(), average='macro')\n",
    "            apc_result = {'max_apc_test_acc': apc_acc, 'max_apc_test_f1': apc_f1}\n",
    "\n",
    "        if eval_emotion:\n",
    "            # Assuming emotion evaluation is based on accuracy\n",
    "            emotion_acc = accuracy_score(test_emotions_all.cpu(), torch.argmax(test_emotion_logits_all, -1).cpu())\n",
    "            emotion_f1 = f1_score(test_emotions_all.cpu(), torch.argmax(test_emotion_logits_all, -1).cpu(),\n",
    "                                  average='macro')\n",
    "            emotion_result = {'max_emotion_test_acc': emotion_acc, 'max_emotion_test_f1': emotion_f1}\n",
    "\n",
    "        return apc_result, ate_result, emotion_result\n",
    "\n",
    "    def save_model(path):\n",
    "        # Save a trained model and the associated configuration,\n",
    "        # Take care of the storage!\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        model_to_save.save_pretrained(path)\n",
    "        tokenizer.save_pretrained(path)\n",
    "        label_map = {i: label for i, label in enumerate(label_list, 1)}\n",
    "        model_config = {\"bert_model\": args.bert_model, \"do_lower\": True, \"max_seq_length\": args.max_seq_length,\n",
    "                        \"num_labels\": len(label_list) + 1, \"label_map\": label_map}\n",
    "        json.dump(model_config, open(os.path.join(path, \"config.json\"), \"w\"))\n",
    "        logger.info('save model to: {}'.format(path))\n",
    "\n",
    "    def train():\n",
    "        train_features = convert_examples_to_features(\n",
    "            train_examples, label_list, args.max_seq_length, tokenizer)\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "        logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
    "        logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "        all_spc_input_ids = torch.tensor([f.input_ids_spc for f in train_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "        all_valid_ids = torch.tensor([f.valid_ids for f in train_features], dtype=torch.long)\n",
    "        all_lmask_ids = torch.tensor([f.label_mask for f in train_features], dtype=torch.long)\n",
    "        all_polarities = torch.tensor([f.polarities for f in train_features], dtype=torch.long)\n",
    "        all_emotions = torch.tensor([f.emotions for f in train_features], dtype=torch.long)\n",
    "        # print(\"Shape of all_spc_input_ids: \", all_spc_input_ids.shape)\n",
    "        # print(\"Shape of all_input_mask: \", all_input_mask.shape)\n",
    "        # print(\"Shape of all_segment_ids: \", all_segment_ids.shape)\n",
    "        # print(\"Shape of all_label_ids: \", all_label_ids.shape)\n",
    "        # print(\"Shape of all_valid_ids: \", all_valid_ids.shape)\n",
    "        # print(\"Shape of all_lmask_ids: \", all_lmask_ids.shape)\n",
    "        # print(\"Shape of all_polarities: \", all_polarities.shape)\n",
    "        # print(\"Shape of all_emotions: \", all_emotions.shape)\n",
    "        train_data = TensorDataset(all_spc_input_ids, all_input_mask, all_segment_ids,\n",
    "                                   all_label_ids, all_polarities, all_valid_ids, all_lmask_ids,\n",
    "                                   all_emotions)\n",
    "\n",
    "        train_sampler = SequentialSampler(train_data)\n",
    "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "        max_apc_test_acc = 0\n",
    "        max_apc_test_f1 = 0\n",
    "        max_ate_test_f1 = 0\n",
    "        max_emotion_test_acc = 0  # Add this line\n",
    "        max_emotion_test_f1 = 0  # Add this line\n",
    "\n",
    "        global_step = 0\n",
    "        for epoch in range(int(args.num_train_epochs)):\n",
    "            logger.info('#' * 80)\n",
    "            logger.info('Train {} Epoch{}'.format(args.seed, epoch + 1, args.data_dir))\n",
    "            logger.info('#' * 80)\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                model.train()\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids_spc, input_mask, segment_ids, label_ids, polarities, valid_ids, l_mask, emotions = batch\n",
    "                # print(f\"Shape of input_ids_spc: {input_ids_spc.shape}\")\n",
    "                # print(f\"Shape of segment_ids: {segment_ids.shape}\")\n",
    "                # print(f\"Shape of input_mask: {input_mask.shape}\")\n",
    "                # print(f\"Shape of label_ids: {label_ids.shape}\")\n",
    "                # print(f\"Shape of polarities: {polarities.shape}\")\n",
    "                # print(f\"Shape of valid_ids: {valid_ids.shape}\")\n",
    "                # print(f\"Shape of l_mask: {l_mask.shape}\")\n",
    "                # print(f\"Shape of emotions: {emotions.shape}\")\n",
    "\n",
    "                loss = torch.tensor(model(input_ids_spc, segment_ids, input_mask, label_ids, polarities,\n",
    "                                          valid_ids, l_mask, emotions), requires_grad=True)\n",
    "                loss.backward()\n",
    "                nb_tr_examples += input_ids_spc.size(0)\n",
    "                nb_tr_steps += 1\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                if global_step % args.eval_steps == 0:\n",
    "                    if epoch >= args.num_train_epochs - 2 or args.num_train_epochs <= 2:\n",
    "                        # evaluate in last 2 epochs\n",
    "                        apc_result, ate_result, emotion_result = evaluate(eval_ATE=not args.use_bert_spc,\n",
    "                                                                          eval_emotion=True)\n",
    "                        if apc_result['max_apc_test_acc'] > max_apc_test_acc:\n",
    "                            max_apc_test_acc = apc_result['max_apc_test_acc']\n",
    "                        if apc_result['max_apc_test_f1'] > max_apc_test_f1:\n",
    "                            max_apc_test_f1 = apc_result['max_apc_test_f1']\n",
    "                        if ate_result > max_ate_test_f1:\n",
    "                            max_ate_test_f1 = ate_result\n",
    "                        if emotion_result['max_emotion_test_acc'] > max_emotion_test_acc:  # Add this line\n",
    "                            max_emotion_test_acc = emotion_result['max_emotion_test_acc']  # Add this line\n",
    "                        if emotion_result['max_emotion_test_f1'] > max_emotion_test_f1:  # Add this line\n",
    "                            max_emotion_test_f1 = emotion_result['max_emotion_test_f1']  # Add this line\n",
    "\n",
    "                        current_apc_test_acc = apc_result['max_apc_test_acc']\n",
    "                        current_apc_test_f1 = apc_result['max_apc_test_f1']\n",
    "                        current_ate_test_f1 = round(ate_result, 2)\n",
    "                        current_emotion_test_acc = emotion_result['max_emotion_test_acc']  # Add this line\n",
    "                        current_emotion_test_f1 = emotion_result['max_emotion_test_f1']  # Add this line\n",
    "\n",
    "                        logger.info('*' * 80)\n",
    "                        logger.info('Train {} Epoch{}, Evaluate for {}'.format(args.seed, epoch + 1, args.data_dir))\n",
    "                        logger.info(f'APC_test_acc: {current_apc_test_acc}(max: {max_apc_test_acc})  '\n",
    "                                    f'APC_test_f1: {current_apc_test_f1}(max: {max_apc_test_f1})')\n",
    "                        if args.use_bert_spc:\n",
    "                            logger.info(f'ATE_test_F1: {current_apc_test_f1}(max: {max_apc_test_f1})'\n",
    "                                        f' (Unreliable since `use_bert_spc` is \"True\".)')\n",
    "                        else:\n",
    "                            logger.info(f'ATE_test_f1: {current_ate_test_f1}(max:{max_ate_test_f1})')\n",
    "                        logger.info(\n",
    "                            f'Emotion_test_acc: {current_emotion_test_acc}(max: {max_emotion_test_acc})  '  # Add this line\n",
    "                            f'Emotion_test_f1: {current_emotion_test_f1}(max: {max_emotion_test_f1})')  # Add this line\n",
    "                        logger.info('*' * 80)\n",
    "        return [max_apc_test_acc, max_apc_test_f1, max_ate_test_f1, max_emotion_test_acc,\n",
    "                max_emotion_test_f1]\n",
    "\n",
    "    return train()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fa8066a6b9e4b34"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cpu\")\n",
    "    n = 5\n",
    "    results = []\n",
    "    max_apc_test_acc, max_apc_test_f1, max_ate_test_f1 = 0, 0, 0\n",
    "    for i in range(n):\n",
    "        seed = i + 1\n",
    "        logger.info('No.{} training process of {}'.format(i + 1, n))\n",
    "        apc_test_acc, apc_test_f1, ate_test_f1 = main()\n",
    "        if apc_test_acc > max_apc_test_acc:\n",
    "                max_apc_test_acc = apc_test_acc\n",
    "            if apc_test_f1 > max_apc_test_f1:\n",
    "                max_apc_test_f1 = apc_test_f1\n",
    "            if ate_test_f1 > max_ate_test_f1:\n",
    "                max_ate_test_f1 = ate_test_f1\n",
    "            logger.info('max_ate_test_f1:{} max_apc_test_acc: {}\\tmax_apc_test_f1: {} \\t'\n",
    "                        .format(max_ate_test_f1, max_apc_test_acc, max_apc_test_f1))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e79fa56ff088c2cc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
