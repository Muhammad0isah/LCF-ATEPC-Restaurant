{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os, sys\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from time import strftime, localtime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import device\n",
    "from transformers.optimization import AdamW\n",
    "from transformers.models.bert.modeling_bert import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from seqeval.metrics import classification_report\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "\n",
    "from utils.data_utils import ATEPCProcessor, convert_examples_to_features\n",
    "from model.lcf_atepc import LCF_ATEPC"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "time = '{}'.format(strftime(\"%y%m%d-%H%M%S\", localtime()))\n",
    "log_file = 'logs/{}.log'.format(time)\n",
    "logger.addHandler(logging.FileHandler(log_file))\n",
    "logger.info('log file: {}'.format(log_file))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6020a397f90923e1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    args = config\n",
    "\n",
    "    if args.gradient_accumulation_steps < 1:\n",
    "        raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\n",
    "            args.gradient_accumulation_steps))\n",
    "\n",
    "    args.train_batch_size = args.train_batch_size // args.gradient_accumulation_steps\n",
    "\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)\n",
    "\n",
    "    processor = ATEPCProcessor()\n",
    "    label_list = processor.get_labels()\n",
    "    num_labels = len(label_list) + 1\n",
    "\n",
    "    args.bert_model = \"bert-base-uncased\"\n",
    "    args.data_dir = \"atepc_datasets/restaurant\"\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(args.bert_model, do_lower_case=True)\n",
    "    train_examples = processor.get_train_examples(args.data_dir)\n",
    "    eval_examples = processor.get_test_examples(args.data_dir)\n",
    "    num_train_optimization_steps = int(\n",
    "        len(train_examples) / args.train_batch_size / args.gradient_accumulation_steps) * args.num_train_epochs\n",
    "    bert_base_model = BertModel.from_pretrained(args.bert_model)\n",
    "    bert_base_model.config.num_labels = num_labels\n",
    "\n",
    "    model = LCF_ATEPC(bert_base_model, args=args)\n",
    "\n",
    "    for arg in vars(args):\n",
    "        logger.info('>>> {0}: {1}'.format(arg, getattr(args, arg)))\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.00001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.00001}\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, weight_decay=0.00001)\n",
    "    eval_features = convert_examples_to_features(eval_examples, label_list, args.max_seq_length,\n",
    "                                                 tokenizer)\n",
    "    all_spc_input_ids = torch.tensor([f.input_ids_spc for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "    all_polarities = torch.tensor([f.polarities for f in eval_features], dtype=torch.long)\n",
    "    all_valid_ids = torch.tensor([f.valid_ids for f in eval_features], dtype=torch.long)\n",
    "    all_lmask_ids = torch.tensor([f.label_mask for f in eval_features], dtype=torch.long)\n",
    "    all_emotions = torch.tensor([f.emotions for f in eval_features], dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_spc_input_ids, all_input_mask, all_segment_ids, all_label_ids,\n",
    "                            all_polarities, all_valid_ids, all_lmask_ids, all_emotions)  # Modify this line\n",
    "    # Run prediction for full data\n",
    "    eval_sampler = RandomSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
    "    return train()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe6ac88579fe943f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "    def evaluate(eval_ATE=True, eval_APC=True, eval_emotion=True):\n",
    "        apc_result = {'max_apc_test_acc': 0, 'max_apc_test_f1': 0}\n",
    "        ate_result = 0\n",
    "        emotion_result = {'max_emotion_test_acc': 0, 'max_emotion_test_f1': 0}\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        n_test_correct, n_test_total = 0, 0\n",
    "        test_apc_logits_all, test_polarities_all = None, None\n",
    "        test_emotion_logits_all, test_emotions_all = None, None\n",
    "        model.eval()\n",
    "        label_map = {i: label for i, label in enumerate(label_list, 1)}\n",
    "        for input_ids_spc, input_mask, segment_ids, label_ids, polarities, valid_ids, l_mask, emotions in eval_dataloader:\n",
    "            input_ids_spc = input_ids_spc.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            valid_ids = valid_ids.to(device)\n",
    "            label_ids = label_ids.to(device)\n",
    "            polarities = polarities.to(device)\n",
    "            l_mask = l_mask.to(device)\n",
    "            emotions = emotions.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                ate_logits, apc_logits, emotion_logits = model(input_ids_spc, segment_ids, input_mask,\n",
    "                                                               valid_ids=valid_ids, polarities=polarities,\n",
    "                                                               attention_mask_label=l_mask, emotions=emotions)\n",
    "            if eval_APC:\n",
    "                polarities = model.get_batch_polarities(polarities)\n",
    "                n_test_correct += (torch.argmax(apc_logits, -1) == polarities).sum().item()\n",
    "                n_test_total += len(polarities)\n",
    "\n",
    "                if test_polarities_all is None:\n",
    "                    test_polarities_all = polarities\n",
    "                    test_apc_logits_all = apc_logits\n",
    "                else:\n",
    "                    test_polarities_all = torch.cat((test_polarities_all, polarities), dim=0)\n",
    "                    test_apc_logits_all = torch.cat((test_apc_logits_all, apc_logits), dim=0)\n",
    "\n",
    "            if eval_emotion:\n",
    "                emotions = model.get_batch_emotions(emotions)\n",
    "                n_test_correct += (torch.argmax(emotion_logits, -1) == emotions).sum().item()\n",
    "                n_test_total += len(emotions)\n",
    "\n",
    "                if test_emotions_all is None:\n",
    "                    test_emotions_all = emotions\n",
    "                    test_emotion_logits_all = emotion_logits\n",
    "                else:\n",
    "                    test_emotions_all = torch.cat((test_emotions_all, emotions), dim=0)\n",
    "                    test_emotion_logits_all = torch.cat((test_emotion_logits_all, emotion_logits), dim=0)\n",
    "\n",
    "            if eval_ATE:\n",
    "                # Assuming ATE evaluation is based on F1 score\n",
    "                ate_f1 = f1_score(label_ids.cpu(), torch.argmax(ate_logits, -1).cpu(), average='macro')\n",
    "                ate_result = max(ate_result, ate_f1)\n",
    "\n",
    "        if eval_APC:\n",
    "            # Assuming APC evaluation is based on accuracy\n",
    "            apc_acc = accuracy_score(test_polarities_all.cpu(), torch.argmax(test_apc_logits_all, -1).cpu())\n",
    "            apc_f1 = f1_score(test_polarities_all.cpu(), torch.argmax(test_apc_logits_all, -1).cpu(), average='macro')\n",
    "            apc_result = {'max_apc_test_acc': apc_acc, 'max_apc_test_f1': apc_f1}\n",
    "\n",
    "        if eval_emotion:\n",
    "            # Assuming emotion evaluation is based on accuracy\n",
    "            emotion_acc = accuracy_score(test_emotions_all.cpu(), torch.argmax(test_emotion_logits_all, -1).cpu())\n",
    "            emotion_f1 = f1_score(test_emotions_all.cpu(), torch.argmax(test_emotion_logits_all, -1).cpu(),\n",
    "                                  average='macro')\n",
    "            emotion_result = {'max_emotion_test_acc': emotion_acc, 'max_emotion_test_f1': emotion_f1}\n",
    "\n",
    "        return apc_result, ate_result, emotion_result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b57009b00f5956e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "    def train():\n",
    "        train_features = convert_examples_to_features(\n",
    "            train_examples, label_list, args.max_seq_length, tokenizer)\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "        logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
    "        logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "        all_spc_input_ids = torch.tensor([f.input_ids_spc for f in train_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "        all_valid_ids = torch.tensor([f.valid_ids for f in train_features], dtype=torch.long)\n",
    "        all_lmask_ids = torch.tensor([f.label_mask for f in train_features], dtype=torch.long)\n",
    "        all_polarities = torch.tensor([f.polarities for f in train_features], dtype=torch.long)\n",
    "        all_emotions = torch.tensor([f.emotions for f in train_features], dtype=torch.long)\n",
    "        # print(\"Shape of all_spc_input_ids: \", all_spc_input_ids.shape)\n",
    "        # print(\"Shape of all_input_mask: \", all_input_mask.shape)\n",
    "        # print(\"Shape of all_segment_ids: \", all_segment_ids.shape)\n",
    "        # print(\"Shape of all_label_ids: \", all_label_ids.shape)\n",
    "        # print(\"Shape of all_valid_ids: \", all_valid_ids.shape)\n",
    "        # print(\"Shape of all_lmask_ids: \", all_lmask_ids.shape)\n",
    "        # print(\"Shape of all_polarities: \", all_polarities.shape)\n",
    "        # print(\"Shape of all_emotions: \", all_emotions.shape)\n",
    "        train_data = TensorDataset(all_spc_input_ids, all_input_mask, all_segment_ids,\n",
    "                                   all_label_ids, all_polarities, all_valid_ids, all_lmask_ids,\n",
    "                                   all_emotions)\n",
    "\n",
    "        train_sampler = SequentialSampler(train_data)\n",
    "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "        max_apc_test_acc = 0\n",
    "        max_apc_test_f1 = 0\n",
    "        max_ate_test_f1 = 0\n",
    "        max_emotion_test_acc = 0  # Add this line\n",
    "        max_emotion_test_f1 = 0  # Add this line\n",
    "\n",
    "        global_step = 0\n",
    "        for epoch in range(int(args.num_train_epochs)):\n",
    "            logger.info('#' * 80)\n",
    "            logger.info('Train {} Epoch{}'.format(args.seed, epoch + 1, args.data_dir))\n",
    "            logger.info('#' * 80)\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                model.train()\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids_spc, input_mask, segment_ids, label_ids, polarities, valid_ids, l_mask, emotions = batch\n",
    "                # print(f\"Shape of input_ids_spc: {input_ids_spc.shape}\")\n",
    "                # print(f\"Shape of segment_ids: {segment_ids.shape}\")\n",
    "                # print(f\"Shape of input_mask: {input_mask.shape}\")\n",
    "                # print(f\"Shape of label_ids: {label_ids.shape}\")\n",
    "                # print(f\"Shape of polarities: {polarities.shape}\")\n",
    "                # print(f\"Shape of valid_ids: {valid_ids.shape}\")\n",
    "                # print(f\"Shape of l_mask: {l_mask.shape}\")\n",
    "                # print(f\"Shape of emotions: {emotions.shape}\")\n",
    "\n",
    "                loss = torch.tensor(model(input_ids_spc, segment_ids, input_mask, label_ids, polarities,\n",
    "                                          valid_ids, l_mask, emotions), requires_grad=True)\n",
    "                loss.backward()\n",
    "                nb_tr_examples += input_ids_spc.size(0)\n",
    "                nb_tr_steps += 1\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                if global_step % args.eval_steps == 0:\n",
    "                    if epoch >= args.num_train_epochs - 2 or args.num_train_epochs <= 2:\n",
    "                        # evaluate in last 2 epochs\n",
    "                        apc_result, ate_result, emotion_result = evaluate(eval_ATE=not args.use_bert_spc,\n",
    "                                                                          eval_emotion=True)\n",
    "                        if apc_result['max_apc_test_acc'] > max_apc_test_acc:\n",
    "                            max_apc_test_acc = apc_result['max_apc_test_acc']\n",
    "                        if apc_result['max_apc_test_f1'] > max_apc_test_f1:\n",
    "                            max_apc_test_f1 = apc_result['max_apc_test_f1']\n",
    "                        if ate_result > max_ate_test_f1:\n",
    "                            max_ate_test_f1 = ate_result\n",
    "                        if emotion_result['max_emotion_test_acc'] > max_emotion_test_acc:  # Add this line\n",
    "                            max_emotion_test_acc = emotion_result['max_emotion_test_acc']  # Add this line\n",
    "                        if emotion_result['max_emotion_test_f1'] > max_emotion_test_f1:  # Add this line\n",
    "                            max_emotion_test_f1 = emotion_result['max_emotion_test_f1']  # Add this line\n",
    "\n",
    "                        current_apc_test_acc = apc_result['max_apc_test_acc']\n",
    "                        current_apc_test_f1 = apc_result['max_apc_test_f1']\n",
    "                        current_ate_test_f1 = round(ate_result, 2)\n",
    "                        current_emotion_test_acc = emotion_result['max_emotion_test_acc']  # Add this line\n",
    "                        current_emotion_test_f1 = emotion_result['max_emotion_test_f1']  # Add this line\n",
    "\n",
    "                        logger.info('*' * 80)\n",
    "                        logger.info('Train {} Epoch{}, Evaluate for {}'.format(args.seed, epoch + 1, args.data_dir))\n",
    "                        logger.info(f'APC_test_acc: {current_apc_test_acc}(max: {max_apc_test_acc})  '\n",
    "                                    f'APC_test_f1: {current_apc_test_f1}(max: {max_apc_test_f1})')\n",
    "                        if args.use_bert_spc:\n",
    "                            logger.info(f'ATE_test_F1: {current_apc_test_f1}(max: {max_apc_test_f1})'\n",
    "                                        f' (Unreliable since `use_bert_spc` is \"True\".)')\n",
    "                        else:\n",
    "                            logger.info(f'ATE_test_f1: {current_ate_test_f1}(max:{max_ate_test_f1})')\n",
    "                        logger.info(\n",
    "                            f'Emotion_test_acc: {current_emotion_test_acc}(max: {max_emotion_test_acc})  '  # Add this line\n",
    "                            f'Emotion_test_f1: {current_emotion_test_f1}(max: {max_emotion_test_f1})')  # Add this line\n",
    "                        logger.info('*' * 80)\n",
    "        return [max_apc_test_acc, max_apc_test_f1, max_ate_test_f1, max_emotion_test_acc,\n",
    "                max_emotion_test_f1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56aead88fa66962f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " def save_model(path):\n",
    "        # Save a trained model and the associated configuration,\n",
    "        # Take care of the storage!\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "        model_to_save.save_pretrained(path)\n",
    "        tokenizer.save_pretrained(path)\n",
    "        label_map = {i: label for i, label in enumerate(label_list, 1)}\n",
    "        model_config = {\"bert_model\": args.bert_model, \"do_lower\": True, \"max_seq_length\": args.max_seq_length,\n",
    "                        \"num_labels\": len(label_list) + 1, \"label_map\": label_map}\n",
    "        json.dump(model_config, open(os.path.join(path, \"config.json\"), \"w\"))\n",
    "        logger.info('save model to: {}'.format(path))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa43bd63dd7b02df"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    experiments = argparse.ArgumentParser()\n",
    "    experiments.add_argument('--config_path', default='experiments.json', type=str,\n",
    "                             help='Path of experiments config file')\n",
    "    experiments = experiments.parse_args()\n",
    "\n",
    "    # from utils.Pytorch_GPUManager import GPUManager\n",
    "\n",
    "    # index = GPUManager().auto_choice()\n",
    "    # device = torch.device(\"cuda:\" + str(index) if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    exp_configs = parse_experiments(experiments.config_path)\n",
    "    n = 5\n",
    "    for config in exp_configs:\n",
    "        logger.info('-' * 80)\n",
    "        logger.info('Config {} (totally {} configs)'.format(exp_configs.index(config) + 1, len(exp_configs)))\n",
    "        results = []\n",
    "        max_apc_test_acc, max_apc_test_f1, max_ate_test_f1 = 0, 0, 0\n",
    "        for i in range(n):\n",
    "            config.device = device\n",
    "            config.seed = i + 1\n",
    "            logger.info('No.{} training process of {}'.format(i + 1, n))\n",
    "            apc_test_acc, apc_test_f1, ate_test_f1 = main(config)\n",
    "\n",
    "            if apc_test_acc > max_apc_test_acc:\n",
    "                max_apc_test_acc = apc_test_acc\n",
    "            if apc_test_f1 > max_apc_test_f1:\n",
    "                max_apc_test_f1 = apc_test_f1\n",
    "            if ate_test_f1 > max_ate_test_f1:\n",
    "                max_ate_test_f1 = ate_test_f1\n",
    "            logger.info('max_ate_test_f1:{} max_apc_test_acc: {}\\tmax_apc_test_f1: {} \\t'\n",
    "                        .format(max_ate_test_f1, max_apc_test_acc, max_apc_test_f1))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "667bb9deb0ed6d7a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Cell 7: Set the configuration parameters and call the main function\n",
    "config = argparse.Namespace()\n",
    "config.dataset = \"restaurant\"\n",
    "config.output_dir = \"output\"\n",
    "config.SRD = 3\n",
    "config.learning_rate = 0.001\n",
    "config.use_unique_bert = False\n",
    "config.use_bert_spc = True\n",
    "config.local_context_focus = \"cdm\"\n",
    "config.num_train_epochs = 10.0\n",
    "config.train_batch_size = 32\n",
    "config.dropout = 0.1\n",
    "config.max_seq_length = 128\n",
    "config.eval_batch_size = 32\n",
    "config.eval_steps = 20\n",
    "config.gradient_accumulation_steps = 1\n",
    "config.config_path = \"experiments.json\"\n",
    "config.device = \"cpu\"\n",
    "config.seed = 1\n",
    "config.bert_model = \"bert-base-uncased\"\n",
    "config.data_dir = \"atepc_datasets/restaurant\"\n",
    "\n",
    "main(config)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df90ceae95b49163"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
